{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting virtual X frame buffer: Xvfb../xvfb: line 24: start-stop-daemon: command not found\r\n",
      ".\r\n"
     ]
    }
   ],
   "source": [
    "# In Google Colab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladislav.vorotilov/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 8\n",
      "n_actions = 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"LunarLander-v2\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy\n",
    "\n",
    "For this assignment we'll utilize the simplified neural network implementation from __[Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)__. Here's what you'll need:\n",
    "\n",
    "* `agent.partial_fit(states, actions)` - make a single training pass over the data. Maximize the probabilitity of :actions: from :states:\n",
    "* `agent.predict_proba(states)` - predict probabilities of all actions, a matrix of shape __[len(states), n_actions]__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='relu',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(np.arange(n_actions), 1, p=probs)[0]\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 0.00315723  1.400161    0.31977257 -0.4781851  -0.0036516  -0.07243331\n",
      "   0.          0.        ]\n",
      " [ 0.00637789  1.3888202   0.32730418 -0.5040601  -0.00882841 -0.10354576\n",
      "   0.          0.        ]\n",
      " [ 0.00969448  1.3768792   0.3393285  -0.5307761  -0.01640998 -0.15164553\n",
      "   0.          0.        ]\n",
      " [ 0.01293211  1.3643439   0.3294093  -0.55719626 -0.02199471 -0.11170511\n",
      "   0.          0.        ]\n",
      " [ 0.01616993  1.351209    0.32942507 -0.58386666 -0.02757999 -0.11171573\n",
      "   0.          0.        ]]\n",
      "actions: [3, 3, 1, 0, 0]\n",
      "reward: -8.635911712907582\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(agent, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "    indices = rewards_batch >= reward_threshold\n",
    "\n",
    "    elite_states = [s for i in range(len(rewards_batch)) if rewards_batch[i] >= reward_threshold for s in states_batch[i]]\n",
    "    elite_actions = [a for i in range(len(rewards_batch)) if rewards_batch[i] >= reward_threshold for a in actions_batch[i]]\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-1000, +1000]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "#     plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.hist(rewards_batch, range=reward_range)\n",
    "#     plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "#                [0], [100], label=\"percentile\", color='red')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='relu',\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -53.291, threshold=23.475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4d3d7f2ef7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#  sessions = [ generate_session(agent, t_max) for _ in range(n_sessions)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msessions_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_max = 10000\n",
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "epoch_mem = 3\n",
    "sessions_history = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(f\"epoch {i}\")\n",
    "    # generate new sessions\n",
    "#     sessions = joblib.Parallel(n_jobs=4)(joblib.delayed(generate_session)(agent, t_max) for _ in range(n_sessions))\n",
    "    sessions = [ generate_session(agent, t_max) for _ in range(n_sessions)]\n",
    "    sessions_history.append(sessions)\n",
    "    if len(sessions_history) > epoch_mem:\n",
    "        sessions_history = sessions_history[-epoch_mem:]\n",
    "    sessions = []\n",
    "    for sess in sessions_history:\n",
    "        sessions += sess\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 50:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladislav.vorotilov/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-eabb1e684e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-eabb1e684e94>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-f5cd21643574>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, t_max)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# ^-- hint: try np.random.choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mnew_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# record sessions like you did before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0moy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdispersion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdispersion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_AWAY\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mimpulse_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mox\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_HEIGHT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplyLinearImpulse\u001b[0m\u001b[0;34m(\u001b[0m           \u001b[0;34m(\u001b[0m \u001b[0mox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplyLinearImpulse\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36m_create_particle\u001b[0;34m(self, mass, x, y, ttl)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mcategoryBits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0x0100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mmaskBits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0x001\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# collide only with ground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                 restitution=0.3)\n\u001b[0m\u001b[1;32m    228\u001b[0m                 )\n\u001b[1;32m    229\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/Box2D/Box2D.py\u001b[0m in \u001b[0;36mCreateDynamicBody\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   6047\u001b[0m         \"\"\"\n\u001b[1;32m   6048\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2_dynamicBody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6049\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6051\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mCreateKinematicBody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/Box2D/Box2D.py\u001b[0m in \u001b[0;36mCreateBody\u001b[0;34m(self, defn, **kwargs)\u001b[0m\n\u001b[1;32m   6108\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6109\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6110\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6111\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFixturesFromShapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapeFixture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapeFixture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/Practical_RL/.env/lib/python3.7/site-packages/Box2D/Box2D.py\u001b[0m in \u001b[0;36mshapes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3844\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3846\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3848\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session(agent) for _ in range(100)]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (up to 6 pt) Devise a way to speed up training against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  \n",
    "__Please list what you did in anytask submission form__. __It's necessary to measure your improvement experimentally__.  __You score depends on this improvement. If the algorithm converges 2x faster, you obtain 3 pts. If the algorithm converges 4x faster, you obtain 6pts__.\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 10% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "plt.imshow(visualize_mountain_car(env, agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ (2 pts) Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ (4 pts) Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * Choose one of [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0) (90+ pts to solve), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) (200+ pts to solve) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
