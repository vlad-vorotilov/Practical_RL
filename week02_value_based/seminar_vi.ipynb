{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov decision process\n",
    "\n",
    "This week's methods are all built to solve __M__arkov __D__ecision __P__rocesses. In the broadest sense, an MDP is defined by how it changes states and how rewards are computed.\n",
    "\n",
    "State transition is defined by $P(s' |s,a)$ - how likely are you to end at state $s'$ if you take action $a$ from state $s$. Now there's more than one way to define rewards, but we'll use $r(s,a,s')$ function for convenience.\n",
    "\n",
    "_This notebook is inspired by the awesome_ [CS294](https://github.com/berkeleydeeprlcourse/homework/blob/36a0b58261acde756abd55306fbe63df226bf62b/hw2/HW2.ipynb) _by Berkeley_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, let's define a simple MDP from this picture:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ad/Markov_Decision_Process.svg\" width=\"400px\" alt=\"Diagram by Waldoalvarez via Wikimedia Commons, CC BY-SA 4.0\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you Colab, uncomment this please\n",
    "# !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week02_value_based/mdp.py\n",
    "\n",
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's2': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use MDP just as any other gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state = s0\n",
      "next_state = s2, reward = 0.0, done = False\n"
     ]
    }
   ],
   "source": [
    "print('initial state =', mdp.reset())\n",
    "next_state, reward, done, info = mdp.step('a1')\n",
    "print('next_state = %s, reward = %s, done = %s' % (next_state, reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it also has other methods that you'll need for Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdp.get_all_states = ('s0', 's1', 's2')\n",
      "mdp.get_possible_actions('s1') =  ('a0', 'a1')\n",
      "mdp.get_next_states('s1', 'a0') =  {'s0': 0.7, 's1': 0.1, 's2': 0.2}\n",
      "mdp.get_reward('s1', 'a0', 's0') =  5\n",
      "mdp.get_transition_prob('s1', 'a0', 's0') =  0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"mdp.get_all_states =\", mdp.get_all_states())\n",
    "print(\"mdp.get_possible_actions('s1') = \", mdp.get_possible_actions('s1'))\n",
    "print(\"mdp.get_next_states('s1', 'a0') = \", mdp.get_next_states('s1', 'a0'))\n",
    "print(\"mdp.get_reward('s1', 'a0', 's0') = \", mdp.get_reward('s1', 'a0', 's0'))\n",
    "print(\"mdp.get_transition_prob('s1', 'a0', 's0') = \",\n",
    "      mdp.get_transition_prob('s1', 'a0', 's0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Visualizing MDPs\n",
    "\n",
    "You can also visualize any MDP with the drawing fuction donated by [neer201](https://github.com/neer201).\n",
    "\n",
    "You have to install graphviz for system and for python. For ubuntu just run:\n",
    "\n",
    "1. `sudo apt-get install graphviz`\n",
    "2. `pip install graphviz`\n",
    "3. restart the notebook\n",
    "\n",
    "__Note:__ Installing graphviz on some OS (esp. Windows) may be tricky. However, you can ignore this part alltogether and use the standart vizualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphviz available: False\n"
     ]
    }
   ],
   "source": [
    "from mdp import has_graphviz\n",
    "from IPython.display import display\n",
    "print(\"Graphviz available:\", has_graphviz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    from mdp import plot_graph, plot_graph_with_state_values, \\\n",
    "        plot_graph_optimal_strategy_and_state_values\n",
    "\n",
    "    display(plot_graph(mdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Now let's build something to solve this MDP. The simplest algorithm so far is __V__alue __I__teration\n",
    "\n",
    "Here's the pseudo-code for VI:\n",
    "\n",
    "---\n",
    "\n",
    "`1.` Initialize $V^{(0)}(s)=0$, for all $s$\n",
    "\n",
    "`2.` For $i=0, 1, 2, \\dots$\n",
    " \n",
    "`3.` $ \\quad V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$, for all $s$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to compute the state-action value function $Q^{\\pi}$, defined as follows\n",
    "\n",
    "$$Q_i(s, a) = \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mdp_get_action_value.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mdp_get_action_value.py\n",
    "\n",
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "    \"\"\" Computes Q(s,a) as in formula above \"\"\"\n",
    "    res = 0\n",
    "    for next_state, transition_prob in mdp.get_next_states(state, action).items():\n",
    "        res += transition_prob * (mdp.get_reward(state, action, next_state) + gamma * state_values[next_state])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdp_get_action_value import get_action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_Vs = {s: i for i, s in enumerate(sorted(mdp.get_all_states()))}\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's2', 'a1', 0.9), 0.69)\n",
    "assert np.isclose(get_action_value(mdp, test_Vs, 's1', 'a0', 0.9), 3.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $Q(s,a)$ we can now define the \"next\" V(s) for value iteration.\n",
    " $$V_{(i+1)}(s) = \\max_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = \\max_a Q_i(s,a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    \"\"\" Computes next V(s) as in formula above. Please do not change state_values in process. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0\n",
    "    \n",
    "    return max(get_action_value(mdp, state_values, state, a_, gamma) for a_ in mdp.get_possible_actions(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Vs_copy = dict(test_Vs)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's0', 0.9), 1.8)\n",
    "assert np.isclose(get_new_state_value(mdp, test_Vs, 's2', 0.9), 1.08)\n",
    "assert test_Vs == test_Vs_copy, \"please do not change state_values in get_new_state_value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's combine everything we wrote into a working value iteration algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 3.50000   |   V(s0) = 0.000   V(s1) = 0.000   V(s2) = 0.000\n",
      "iter    1   |   diff: 0.64500   |   V(s0) = 0.000   V(s1) = 3.500   V(s2) = 0.000\n",
      "iter    2   |   diff: 0.58050   |   V(s0) = 0.000   V(s1) = 3.815   V(s2) = 0.645\n",
      "iter    3   |   diff: 0.43582   |   V(s0) = 0.581   V(s1) = 3.959   V(s2) = 0.962\n",
      "iter    4   |   diff: 0.30634   |   V(s0) = 0.866   V(s1) = 4.395   V(s2) = 1.272\n",
      "iter    5   |   diff: 0.27571   |   V(s0) = 1.145   V(s1) = 4.670   V(s2) = 1.579\n",
      "iter    6   |   diff: 0.24347   |   V(s0) = 1.421   V(s1) = 4.926   V(s2) = 1.838\n",
      "iter    7   |   diff: 0.21419   |   V(s0) = 1.655   V(s1) = 5.169   V(s2) = 2.075\n",
      "iter    8   |   diff: 0.19277   |   V(s0) = 1.868   V(s1) = 5.381   V(s2) = 2.290\n",
      "iter    9   |   diff: 0.17327   |   V(s0) = 2.061   V(s1) = 5.573   V(s2) = 2.481\n",
      "iter   10   |   diff: 0.15569   |   V(s0) = 2.233   V(s1) = 5.746   V(s2) = 2.654\n",
      "iter   11   |   diff: 0.14012   |   V(s0) = 2.389   V(s1) = 5.902   V(s2) = 2.810\n",
      "iter   12   |   diff: 0.12610   |   V(s0) = 2.529   V(s1) = 6.042   V(s2) = 2.950\n",
      "iter   13   |   diff: 0.11348   |   V(s0) = 2.655   V(s1) = 6.168   V(s2) = 3.076\n",
      "iter   14   |   diff: 0.10213   |   V(s0) = 2.769   V(s1) = 6.282   V(s2) = 3.190\n",
      "iter   15   |   diff: 0.09192   |   V(s0) = 2.871   V(s1) = 6.384   V(s2) = 3.292\n",
      "iter   16   |   diff: 0.08272   |   V(s0) = 2.963   V(s1) = 6.476   V(s2) = 3.384\n",
      "iter   17   |   diff: 0.07445   |   V(s0) = 3.045   V(s1) = 6.558   V(s2) = 3.467\n",
      "iter   18   |   diff: 0.06701   |   V(s0) = 3.120   V(s1) = 6.633   V(s2) = 3.541\n",
      "iter   19   |   diff: 0.06031   |   V(s0) = 3.187   V(s1) = 6.700   V(s2) = 3.608\n",
      "iter   20   |   diff: 0.05428   |   V(s0) = 3.247   V(s1) = 6.760   V(s2) = 3.668\n",
      "iter   21   |   diff: 0.04885   |   V(s0) = 3.301   V(s1) = 6.814   V(s2) = 3.723\n",
      "iter   22   |   diff: 0.04396   |   V(s0) = 3.350   V(s1) = 6.863   V(s2) = 3.771\n",
      "iter   23   |   diff: 0.03957   |   V(s0) = 3.394   V(s1) = 6.907   V(s2) = 3.815\n",
      "iter   24   |   diff: 0.03561   |   V(s0) = 3.434   V(s1) = 6.947   V(s2) = 3.855\n",
      "iter   25   |   diff: 0.03205   |   V(s0) = 3.469   V(s1) = 6.982   V(s2) = 3.891\n",
      "iter   26   |   diff: 0.02884   |   V(s0) = 3.502   V(s1) = 7.014   V(s2) = 3.923\n",
      "iter   27   |   diff: 0.02596   |   V(s0) = 3.530   V(s1) = 7.043   V(s2) = 3.951\n",
      "iter   28   |   diff: 0.02336   |   V(s0) = 3.556   V(s1) = 7.069   V(s2) = 3.977\n",
      "iter   29   |   diff: 0.02103   |   V(s0) = 3.580   V(s1) = 7.093   V(s2) = 4.001\n",
      "iter   30   |   diff: 0.01892   |   V(s0) = 3.601   V(s1) = 7.114   V(s2) = 4.022\n",
      "iter   31   |   diff: 0.01703   |   V(s0) = 3.620   V(s1) = 7.133   V(s2) = 4.041\n",
      "iter   32   |   diff: 0.01533   |   V(s0) = 3.637   V(s1) = 7.150   V(s2) = 4.058\n",
      "iter   33   |   diff: 0.01380   |   V(s0) = 3.652   V(s1) = 7.165   V(s2) = 4.073\n",
      "iter   34   |   diff: 0.01242   |   V(s0) = 3.666   V(s1) = 7.179   V(s2) = 4.087\n",
      "iter   35   |   diff: 0.01117   |   V(s0) = 3.678   V(s1) = 7.191   V(s2) = 4.099\n",
      "iter   36   |   diff: 0.01006   |   V(s0) = 3.689   V(s1) = 7.202   V(s2) = 4.110\n",
      "iter   37   |   diff: 0.00905   |   V(s0) = 3.699   V(s1) = 7.212   V(s2) = 4.121\n",
      "iter   38   |   diff: 0.00815   |   V(s0) = 3.708   V(s1) = 7.221   V(s2) = 4.130\n",
      "iter   39   |   diff: 0.00733   |   V(s0) = 3.717   V(s1) = 7.230   V(s2) = 4.138\n",
      "iter   40   |   diff: 0.00660   |   V(s0) = 3.724   V(s1) = 7.237   V(s2) = 4.145\n",
      "iter   41   |   diff: 0.00594   |   V(s0) = 3.731   V(s1) = 7.244   V(s2) = 4.152\n",
      "iter   42   |   diff: 0.00534   |   V(s0) = 3.736   V(s1) = 7.249   V(s2) = 4.158\n",
      "iter   43   |   diff: 0.00481   |   V(s0) = 3.742   V(s1) = 7.255   V(s2) = 4.163\n",
      "iter   44   |   diff: 0.00433   |   V(s0) = 3.747   V(s1) = 7.260   V(s2) = 4.168\n",
      "iter   45   |   diff: 0.00390   |   V(s0) = 3.751   V(s1) = 7.264   V(s2) = 4.172\n",
      "iter   46   |   diff: 0.00351   |   V(s0) = 3.755   V(s1) = 7.268   V(s2) = 4.176\n",
      "iter   47   |   diff: 0.00316   |   V(s0) = 3.758   V(s1) = 7.271   V(s2) = 4.179\n",
      "iter   48   |   diff: 0.00284   |   V(s0) = 3.762   V(s1) = 7.275   V(s2) = 4.183\n",
      "iter   49   |   diff: 0.00256   |   V(s0) = 3.764   V(s1) = 7.277   V(s2) = 4.185\n",
      "iter   50   |   diff: 0.00230   |   V(s0) = 3.767   V(s1) = 7.280   V(s2) = 4.188\n",
      "iter   51   |   diff: 0.00207   |   V(s0) = 3.769   V(s1) = 7.282   V(s2) = 4.190\n",
      "iter   52   |   diff: 0.00186   |   V(s0) = 3.771   V(s1) = 7.284   V(s2) = 4.192\n",
      "iter   53   |   diff: 0.00168   |   V(s0) = 3.773   V(s1) = 7.286   V(s2) = 4.194\n",
      "iter   54   |   diff: 0.00151   |   V(s0) = 3.775   V(s1) = 7.288   V(s2) = 4.196\n",
      "iter   55   |   diff: 0.00136   |   V(s0) = 3.776   V(s1) = 7.289   V(s2) = 4.197\n",
      "iter   56   |   diff: 0.00122   |   V(s0) = 3.778   V(s1) = 7.291   V(s2) = 4.199\n",
      "iter   57   |   diff: 0.00110   |   V(s0) = 3.779   V(s1) = 7.292   V(s2) = 4.200\n",
      "iter   58   |   diff: 0.00099   |   V(s0) = 3.780   V(s1) = 7.293   V(s2) = 4.201\n",
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "gamma = 0.9            # discount for MDP\n",
    "num_iter = 100         # maximum iterations, excluding initialization\n",
    "# stop VI if new values are this close to old values (or closer)\n",
    "min_difference = 0.001\n",
    "\n",
    "# initialize V(s)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "# if has_graphviz:\n",
    "#     display(plot_graph_with_state_values(mdp, state_values))\n",
    "\n",
    "for i in range(num_iter):\n",
    "\n",
    "    # Compute new state values using the functions you defined above.\n",
    "    # It must be a dict {state : float V_new(state)}\n",
    "    new_state_values = {\n",
    "        s: get_new_state_value(mdp, state_values, s, gamma)\n",
    "        for s in mdp.get_all_states()\n",
    "    }\n",
    "\n",
    "    assert isinstance(new_state_values, dict)\n",
    "\n",
    "    # Compute difference\n",
    "    diff = max(abs(new_state_values[s] - state_values[s])\n",
    "               for s in mdp.get_all_states())\n",
    "    print(\"iter %4i   |   diff: %6.5f   |   \" % (i, diff), end=\"\")\n",
    "    print('   '.join(\"V(%s) = %.3f\" % (s, v) for s, v in state_values.items()))\n",
    "    state_values = new_state_values\n",
    "\n",
    "    if diff < min_difference:\n",
    "        print(\"Terminated\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_graphviz:\n",
    "    display(plot_graph_with_state_values(mdp, state_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state values: {'s0': 3.7810348735476405, 's1': 7.294006423867229, 's2': 4.202140275227048}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final state values:\", state_values)\n",
    "\n",
    "assert abs(state_values['s0'] - 3.781) < 0.01\n",
    "assert abs(state_values['s1'] - 7.294) < 0.01\n",
    "assert abs(state_values['s2'] - 4.202) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use those $V^{*}(s)$ to find optimal actions in each state\n",
    "\n",
    " $$\\pi^*(s) = argmax_a \\sum_{s'} P(s' | s,a) \\cdot [ r(s,a,s') + \\gamma V_{i}(s')] = argmax_a Q_i(s,a)$$\n",
    " \n",
    "The only difference vs V(s) is that here we take not max but argmax: find action such with maximum Q(s,a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma=0.9):\n",
    "    \"\"\" Finds optimal action using formula above. \"\"\"\n",
    "    if mdp.is_terminal(state):\n",
    "        return None\n",
    "    return max((get_action_value(mdp, state_values, state, a_, gamma), a_) for a_ in mdp.get_possible_actions(state))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_optimal_action(mdp, state_values, 's0', gamma) == 'a1'\n",
    "assert get_optimal_action(mdp, state_values, 's1', gamma) == 'a0'\n",
    "assert get_optimal_action(mdp, state_values, 's2', gamma) == 'a1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'has_graphviz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f47d523c95b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mhas_graphviz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_graph_optimal_strategy_and_state_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run the cell that starts with \\\"%%writefile mdp_get_action_value.py\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'has_graphviz' is not defined"
     ]
    }
   ],
   "source": [
    "if has_graphviz:\n",
    "    try:\n",
    "        display(plot_graph_optimal_strategy_and_state_values(mdp, state_values))\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Run the cell that starts with \\\"%%writefile mdp_get_action_value.py\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward:  0.4924\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "\n",
    "s = mdp.reset()\n",
    "rewards = []\n",
    "for _ in range(10000):\n",
    "    s, r, done, _ = mdp.step(get_optimal_action(mdp, state_values, s, gamma))\n",
    "    rewards.append(r)\n",
    "\n",
    "print(\"average reward: \", np.mean(rewards))\n",
    "\n",
    "assert(0.40 < np.mean(rewards) < 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mdp import FrozenLakeEnv\n",
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "\n",
    "mdp.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp, state_values=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" performs num_iter value iteration steps starting from state_values. Same as before but in a function \"\"\"\n",
    "    state_values = state_values or {s: 0 for s in mdp.get_all_states()}\n",
    "    for i in range(num_iter):\n",
    "\n",
    "        # Compute new state values using the functions you defined above. It must be a dict {state : new_V(state)}\n",
    "        new_state_values = {\n",
    "            s: get_new_state_value(mdp, state_values, s, gamma)\n",
    "            for s in mdp.get_all_states()\n",
    "        }\n",
    "\n",
    "        assert isinstance(new_state_values, dict)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = max(abs(new_state_values[s] - state_values[s])\n",
    "                   for s in mdp.get_all_states())\n",
    "\n",
    "        print(\"iter %4i   |   diff: %6.5f   |   V(start): %.3f \" %\n",
    "              (i, diff, new_state_values[mdp._initial_state]))\n",
    "\n",
    "        state_values = new_state_values\n",
    "        if diff < min_difference:\n",
    "            break\n",
    "\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    }
   ],
   "source": [
    "state_values = value_iteration(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*FFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "right\n",
      "\n",
      "S*FF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "right\n",
      "\n",
      "SF*F\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FH*H\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FF*H\n",
      "HFFG\n",
      "\n",
      "down\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF*G\n",
      "\n",
      "right\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = mdp.reset()\n",
    "mdp.render()\n",
    "for t in range(100):\n",
    "    a = get_optimal_action(mdp, state_values, s, gamma)\n",
    "    print(a, end='\\n\\n')\n",
    "    s, r, done, _ = mdp.step(a)\n",
    "    mdp.render()\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize!\n",
    "\n",
    "It's usually interesting to see what your algorithm actually learned under the hood. To do so, we'll plot state value functions and optimal actions at each VI step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def draw_policy(mdp, state_values):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    h, w = mdp.desc.shape\n",
    "    states = sorted(mdp.get_all_states())\n",
    "    V = np.array([state_values[s] for s in states])\n",
    "    Pi = {s: get_optimal_action(mdp, state_values, s, gamma) for s in states}\n",
    "    plt.imshow(V.reshape(w, h), cmap='gray', interpolation='none', clim=(0, 1))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticks(np.arange(h)-.5)\n",
    "    ax.set_yticks(np.arange(w)-.5)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    Y, X = np.mgrid[0:4, 0:4]\n",
    "    a2uv = {'left': (-1, 0), 'down': (0, -1), 'right': (1, 0), 'up': (0, 1)}\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            plt.text(x, y, str(mdp.desc[y, x].item()),\n",
    "                     color='g', size=12,  verticalalignment='center',\n",
    "                     horizontalalignment='center', fontweight='bold')\n",
    "            a = Pi[y, x]\n",
    "            if a is None:\n",
    "                continue\n",
    "            u, v = a2uv[a]\n",
    "            plt.arrow(x, y, u*.3, -v*.3, color='m',\n",
    "                      head_width=0.1, head_length=0.1)\n",
    "    plt.grid(color='b', lw=2, ls='-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 0\n",
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 1\n",
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAL5klEQVR4nO3dfWxV9R3H8fe5LffSC+VSqIg0yLVY24mu3IokgGTBGAJEghHcIESnEHlISNxMFpfNLChTNhMXYpiKibjxB/AHRjCMMaNDwyYhQxvG1BZmHWApgVoehJY+wNkf59JLofTxPN1fPy9yQ+/p6Tnf3n56es655/y+lm3biJgiEnQBIm5SoMUoCrQYRYEWoyjQYpTc7mawLGsZsMx5NuQ+KPO4JJGe+Azbtq3rp1q9OW1nWZNs+MzVstxz9fu44XsMEdXops4CrV0OMYoCLUYJLNDP8AzrWBfU6nvkLd7iKZ4KuoybSpDgPd7jfu4PupSbqqCC7WyngAJf1hdIoAspZDazKaWUcsqDKKFb05jGWMbyGI+RT37Q5XRqMYvJJ5+VrAy6lJtayUqGMpQneMKX9QUS6Cd5EguLwQxmBSuCKKFby1nOYAYTIcJCFgZdzg0SJJjLXHLI4VZuDeVWuoIKiigihxxmM9uXrbTvgS6kkJnMJEoUgGKKQ7eVnspURjEKgBgx5jM/dFvpxSwmkv7xxYmHciu9kpXkkQdAhAiP87jn6/Q90AkSXOBC+/MmmhjBCL/L6NJIRnKJS+3PL3IxdIFOkKCJJgBaaQUgt/u3FXwTIYKFRTPNADTSyDCGeb9i27Z7/ID7bJwTlf1+bGSjvYc9ri0P7PTDreVh72GPvZa1oa+xnPLQ1lhGmcs/58yjs4zqtJ0YRYEWoyjQYhQFWoyiQItRFGgxSjCXjxZAxcwKam6v4WzsLDQCp4C/AGf6utCr34cLlz3+DBjeyfQ3gZP9WfAAqtGz+jI6u3w0mDPxP4HPR39OqiZF5XeVMAwYB+TTj0C7b0r1FKwzFp/yqTPhYrD1dGZK9RSOnDlCPfXOhJDVOKR6CLPOzOJd3nUmeFyf/4HOA0ZDvCnOq5te5UEedKbnELodoDmVc8itys0EOoTmVM5hW9W2TKBDZnjlcFZVrcoE2mP+B7rZeTTmNfL0iqfhG+Ao8DWk38ENjV2pXVjJa/6q7Q6slJvaldpFbbI2MyFkNZ5NnWV9cn1mgsf1BbMPPQGic6O0DG7JTLsAbAZO9HWhPuyfru7vggdQjZ7VlxGefegvoKW6BWuchT3OhgpgKPAjYEsgFXXK2mphV/X8Fz4Ioa9xK0SqIlzhii+r83+vNQLcDrSB/bUNfwf+kf5c1PdqumQT4qCkZUONfoUZgthC5wJLgNNAHc5+8w/Sn6vxvRoxjP+BbgP2AUmgBBgEnAf+BfzT92rEMBqXw1eq0U0al0OMp0CLURRoMYoCLUZRoMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSgKtBilD9dDh/0OibDXB6rRDZ1f3trtFtqyrGWWZR2wLOuAc5uJSHjpAn9fqUY36QJ/MV5ggR7KUN9618nAEVigV7OaDWxo7+Qk4oZA0lRCCROYwFCGZsa2E3FBIIFeznKiRMkjj2Us01ZaXON7kkooIUWqPcQFFGgrLa7xPdANNHQYnnY/+6mltouvEOm5wM5Db2Qjd3AHM5jhyvKy4/ypanSTzkOL8RRoMYoCLUZRoMUoCrQYRYEWo/h/2i5bGkZuBarS05LAk8Al4Hf9WfgAbLzpyevoCE/TIKC8upw7z9zpW0NGY1XTsVnpAH8dAwv09MrpzK+a71tDRmNVktkCSnCB3pvaS12yLjMhZA0jSeH8iQSndXNIWSkLO3nNbuMAfx0DC/TB0oMc5GBmQth+EKVBF9Azdul1x0AD/HUMLNAdDhbCqLODmRBas3UN26q2ddw4hInPr6NO24lRFGgxigItZrFtu8cPuM/GOfMewoedfgRdh7817mGPXU55qGv06tFZRrWFFqMo0GIUBVqMokCLURRoMYoCLUbRcLq+cq/G53meyUwmn3wuc5laalnKUtpo6+eSs+F1dGgYA4Oc5jQxYgDkkENb+t9Ap0BnqS1s4QpXAGiiiTd4I+CKwkGBzlLnOc92tnOZy9RRxwEOBF1SKCjQWWwLWzjLWV7n9aBLCQ0dFPpKNbpJB4ViPAVajKLGm4FQjf2nxpsyAOig0FdOjSdO1HUzX3DGjLkt/VGYX0eHDgrFeIEFuphiJjIxqNWLoQIbl+MFXmAkI5nPfJpoCqoMMUwgW+hpTGMEI7CwWMCCIEoQQwUS6BWsIE6cwQxmIQvJIy+IMsRAvgc6RYoxjKGFFtpoI0qUWczyuwwxlO+B/pIveY3XiBIll1zWs5697PW7DDGU74Fuppkd7OAbvgFgBzuop97vMsRQOg8tRlGgxSgKtBhFgRajKNBiFAVajOL/tRzphoxLWNJxer8bRrrIs6aW7pm8eTLfXvj2hukfPPoB9xTeE0BF1/Gh8WZn1HizK71saplDDsUUc4QjXlbVwUO3P0RyWLL9+ci8kb6tO4zUeLMrvWxqOYc5PMuzVFHFm7zpS2eqRWWLmJ2c7fl6skVggf4k9Um4G28CsVSMimQFVvrujbm753Y5fwUVtNBCGWWsZS1HOcrLvMxxjntW4+bPN7PvxL725y9OfdGzdfXJQGm8eaj0EIc4lJkQwkA3lzazj0xYXtr9Urdfc3V8uQgRxjOe0Yz2NNAf1X/EtVcOhC7QarwZItfVOIMZXc4+j3msYhWXuMT7vM9mNnOOc56WuGbrGhb9dhHxqXFP19NnPjfeDC7QBtrPfhIk2MEOz4MsnVOgXXSSk2xiU9BlDGh6Y0WMonE5fOX+uBzVY6oZu22sa/vQGpdDJEQUaDGKAi1GUaDFKAq0GEWBzlKXz1+m9XgrAK11rbSdVks30BsrWav2p7U0VTpjAp78+UmsQRYlX5VgRcN/us1L2kJnqfx5+Vi56fBegfgD8QEfZlCgs1ZiUQIr5gTYilrc8qtbAq4oHBToLBWJRSj8RSFEID49Tqw0FnRJoaB96CyWWJSgcW8jhc8VBl1KaCjQWSwSi1D0dlHQZYSKdjnEKAq0GEWNNwOQuUQzzML+OqrxpgwAxl3gnw1NLXvxkvvOat/whf9NGl3gL8ZToMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSgKtBhFgRajKNBiFH9vwQqod11vhb4HIJBcl+TouaM3TK9cXsnE0RMDqKgTRcADwFggD2gETgEHgK+8WaXuKexCNvQAfPiuhxlfML79+S3xkAxncDewAGcf4DRwGIjhhPxeFOgg9LYHYGtdK9/v/J7EwgQ5+TkeVpaxNLWUR8oe6fH85/ado+nrJkYtHEUk16M9zkHAwzhhPgS8B1xJf84CPLxJPZhA+9y7rq+2VG3pVQ/AC3+7wOkXT1P/Sj0jVo6g4OkCz4P9duXbfPy/j9ufr5u1rsv5j609RsNfG6h5robi3xd7E+yxwNWGAp+QCTM492F4eONTMIH2uXddX3147MMOzxcvWNz9F+WAfdGmYX0DDX9soOjPRQx5YIhHFcLOwzs7PH9kds+21i0nWji84jA1v6xh0meTiN4ada+oa7/ds+n/H8LZn75qtXuru1Ywgfa5d11fbZiwgXvX3IvdnL5nqptfxJbqFufP7GUgB3JH5ZIzwtst9Dtj3+HuP9ydmTCh6/kbv2h0PrBwxsQr82BMvGt7og8DGoBjwL+BH7q7qutpH7oLuUW5JHcnezz/mT+d4dSvTzHojkGM+s0ohswcgmV5e2/e8KnDmbxkco/nPzTvEN/t/I7hM4Yz/pXx5Ffku1/UcZwzGnFgOrAD56DwPAp0Nkn8OEGsJEbe1DzPg9xXd71xFy2rW8hPeRDkq1qBXcCjOMdLtwHfAgnvVnmVAu2iSDxCfFpIWxSnxcbEiI3xYWDH/+BskafhHCROxNkV+S/whXer1TAGPtIwBu7SMAZiPAVajKJAi1EUaDGKAi1GUaDFKAq0GEWBFqMo0GIUBVqMokCLURRoMYoCLUZRoMUoCrQYpZfXQ1vfA9XeldNvhUB90EV0QzW6Y5xt2zcMQtLbO1aqbdue5FJBrrMs60CY6wPV6DXtcohRFGgxSm8D/ZYnVbgn7PWBavRUrw4KRcJOuxxiFAVajKJAi1EUaDGKAi1G+T8nTdg0MtGf9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 2\n",
      "iter    0   |   diff: 0.81000   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 3\n",
      "iter    0   |   diff: 0.72900   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 4\n",
      "iter    0   |   diff: 0.65610   |   V(start): 0.000 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANT0lEQVR4nO3de3BW9Z3H8fc5zxOeXAi5EFNMlERSFGldRS66YBVmlaLLroxjW7PWoUrXQlu6ShftuDMrI62u/uE47e4w7VRdlx2S2dkdth2LlNqWDnUYXS4dKQi0RAW5GG4h9+TJc87+cXIhJCR5Qs7l+eXzmmHIeThnzjeHT375PZfz+1qu6yJiCjvsAkTGkgItRlGgxSgKtBhFgRajxIfbwbKsx4HHva282TDD55JEhjdx4iGampqsSx+30nnZzrLmuLB7TAsbO973UVNTG3Idl1dd/RAA27b9KuRKLm/x4nuAaF9HgGeeeYa6uroBgdaUQ4yiQItRFGgxigItRlGgxSgKtBhFgRajKNBiFAVajKJAi1EUaDGKAi1GUaDFKAq0GGXYz0P7oghYDEwFEkArUA/8AjgfSkX9rD6ymjNdZwY8/kLFC1RmVwZf0CAe2f0In3Z8OuDxDTdvoCqvKoSK+gvrGoYT6K8AU4A64CwwCagA8olEoHvcmncrpRNKe7cnxSaFWM3gbiu6jbLsst7tgnhBiNUMFPQ1DD7QOXhhbgP+46LHYww5ASqiiB/wA7awha1spYsuX8sEWFiwkLn5c0e8f9bBLPL/M5/mB5vpvLkTBnz8fOwtKV3CgskL/D8RED8WZ2LNRDpndNL6t60jOibda3ilgg90R/efHGAl8CHwMXAESF7+sGKKmcY0VrGKFazgNV7jLd7yNdjbL2znQNuB3u3lpcuH3D9+NE7Wh1kUvlJIqiRF01ebfA/21vqtvN/4fu/2qutWjfk54sfiTNw0kcT+hPd/lGLEgU73Gl6p4APtAD8H+29snCmON1r/JRQ1F/H8pueZcWL4exZzyeUJnmAmM3mRF30rdU/LHmjp2376H54e9hjXcrE7bOzjNsUvFtOwsoH2u9p9q/Hd8+/22x7rQNunbUqeKsHFxer+ycx+P5sp1VOGPC72RAwKB15D8wINsB+cQw7lFeW0V7TTcGsD5yeeZ+1da7mm5ppBD6mggid5EhsbB4cd7OAN3vC1zDWla5h/dn7v9tn1Z4fcP3tHNrm/ycWxHbCg5b4WOuZ2+Frj+tr13L7idtyb/VnSzZns0LCygfzafKw2C7vDJnltksbHG4c+LuUA8JT9FLOvmo1T6PhS36WCD7QNXAMcheNHjntTjVZgCTRPaOYgBwc9rIGG3iC/xmuc5KT/tcYh+dkh5kGXsM/Z5Pwuh5b7Wmj961bcPAPWDbSh/a522u9oJ/v32eTX5pP8bHLY6+IecaELuqZ04eQHE2YII9Bx4DHgNHASb052Y/e/1V3+sFOcYilLcQju4qSrY14H9bPrvSe4pon1BTvK714EH+guYCdQCUwHsoBG4P+Ad4Y+NMph7mVimC8W8e8vnCeFvwz8rGn5UdWPwi5hWBtnbwQga11WIC9hpiusaxjhXx4i6VOgxSgKtBhFgRajKNBiFAVajBLOW99yxez/trF2e5+tiP0whnOjg7PGGfdDlAKdoaz9FtYeL9DWMQu70cZxFOhx/u1nrtSjKe9dVsDNdkk9ltLwhAKduaaCO9fFtVxIgHuPAR+EGgMKdAZLPZry/tbo3EuXIZNNha6NXTA57EKiQ4HOdKXD7zKeaMohRhlFW7ddPpYjMlIWruum39bNsqzHLcvaZVnWLu82E5HoSnuErqn5Rx/LGb2eppaBLIYxat613rv3DyHXcXmzZt3S/VWUr6NnVCO0SCZRoMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSgKtBhFgRajKNBiFAVajBL4LViRb2r5BFAI1EJvd4xK4GtAO/AvoVQ1wH3b7uNk28C2HLULa7mh4IYQKrpESNcxtHsKM6GpZSa48zN3ck1eX6OloglFIVYTvtACHXRDRlMtq1jGoqsXhV1GZIQW6O0XtnOg5UDvLN7v/nVpm4X3KxK81s0Rtfmjzew603ef59qb1oZYzSACvo6hBXpPy55+25ELdASmoSOxo34H1PdtRy7QAV/H0AL97K+eZeE7CzlVcyqsEoY22JOZCFpfu54vfveLZM3JCruUwQV8HfWynRhFgRajKNBilMDn0D0NGSf/NKIrDL4yyGMfAeuCLWM4WxZvAaBhXUPIlVxGSNdRI7QYRYEWoyjQYhQFWoyiQItRFGgxSuCBjn8Yp/TrpWR94r1VW7qilOx3soMuI+O1fK+Fhju9l+xavtFC47JG3KQ6YQUeaKfAweroW9bXSlqkJqeCLiPj2aW290F5AAevZ6E65oQQ6GKHtrvacOMuLi7JiiTJGcmgy8h4iUcTEOveyIGcNTlYVvQXKfdbKHPo5geavQXiJ0DTw01hlJDx7CKbxJcSYINdbhO/XcMzhBRop9ih9a9a6ZzeqdH5CiQeTWAVWeR8V6Nzj9B+rJuWa2S+UnaRTcHbBWGXESl62U6MokCLUdR4UzKUGm/KOJD2CL1t2ws+ljN6ixffA2RGU8sTJwaueBQVZWVXd38V/VdN1HhTjKdAi1EUaDGKAi1GUaDFKAq0GEWBFqMo0GIUBVqMokCLURRoMYoCLUZRoMUoCrQYJfB7Ch/Z/Qifdnw64PENN2+gKq8q6HIGFfmmlsC8TfP4pPmTAY9ve2Abny/5fAgVXWK8Nd68reg2yrLLercL4sPc7OkCfwKq6FuPwmfpNrV0ky6pP6eI3xjcZb176t1UTqrs3Z6cE9GF5AMSWqCXlC5hweQFIz/gI8j6dhbuZJfUihTuItf3YKfb1LLzfztpe76N2MwYOU/mEJ/j/+WtnlHNvZX3+n6eTBFaoLee3Mq+3+6DDm/7Wwe+NeT+Vr2Fa7lYZy1iP4zBq5Bak8Kd6996bpsPbmbn/+z0ltoCvnP4O0Pu3/VeF2RB6kCK5tXNxKbFyP1+LrHr/PvJ27RnEztP7Ozdfm7+c76da1TGS+PNdxvfhb4ZB6vfWD3ygzuBJFgfWL4GekfjDri2b/ubr39z+IN6sutA6k8pUidSvgb612d+DWf6tiMX6HHTePOGZ/tNOZLbhllB6QjEvx2HGLizvWkHU/2t8eV5L/efctw/9P4d/9VB20ttkIDEgwkSjyWwi/19IWl97Xqqv19N7vxcX88zagE33sycBdHKwHnIwVnk+B7k0YoviJP4eoLEl/0PsgwucwKdA85yJ+wqhhQrj5GzMifsMsY1DSNilMBH6I2zNwZ9yrT1NLWMsvf+7j0ADq07FHIll6HGmyJXToEWoyjQYhQFWoyiQItRFOgMlWpMkTzmvbuaPJmk63RXyBVFQ+a8sSL9HF9+nLa9bQCcevIUVpbF9A+mY02I/jK4ftIInaHy78/HineH14HcO3LHfZhBgc5YBdUFWAkvwNYEi6ueuSrkiqJBgc5QdsKmZG0J2JD7hVwSNyTCLikSNIfOYAXVBbTuaKXk6ZKwS4kMBTqD2Qmb8lfLwy4jUjTlEKMo0GIUNd6UDKXGmzIOjGKE3u1jOVfC+z4yoallGpc8cFbvmBf9N2nUeFOMp0CLURRoMYoCLUZRoMUoCrQYRYEWoyjQYhQFWoyiQItRFGgxigItRlGgxSjB3oIVUu+6dEW+ByBQ+UolH1/4eMDje7+xl1um3BJCRYMoB+7A61OTA7QC9Xgfqf/An1PqnsIhZEIPwKXXL6WqqK9h6VW5EVnOYCbwIN4c4DRwGEjghfwmFOgwpNsDMHkySdObTRQ8VEAsP5juoCtmrWDZjGUj3v/Czgu0HWmj9KFS7LhPM84sYClemPcBm+ltjYcF+HiTejiBDrh33WjVHKxJqwdg8y+bOf3cac68dIbiVcUU/X2R78F+de+rbP9oe+/2K0sGWzq/z9EXjnLurXPUPV3HtBen+RPsa4Geply/oy/M4N2H4eONT+EEOhrtsof19tG3+20//ODDwx8UA7fF5dy/nuPcv52j/I1y8u7I86lCePPwm/22l907stG680Qnh1cepu57dczZPYcJn5kwdkVd/O02dP99N958use6sTvdxcIJdMC960brx5/7MTetvwm3o/ueqWF+EDsPdXq/ZlNADOKlcWLF/o7Qr1/7OjNfntn3wOeG3r91f6v3hYW3Jt4MH9bEa7no60nAOeAo8D7wF2N7qktpDj2EeHmcyq2VI97//L+fp/6f6sm6LovSfy4lb3EeluXvvXmF8wuZ99i8Ee+/7/59nH3zLIWLCql6qYr8W/PHvqhjeK9o5AJfAH6G96SwEQU6kxR8uYDE9AQ583N8D/JoXb/hejrXdZI/y4cg90gCW4AH8J4vXQ18AhT4d8oeCvQYsnNtchdEtEVxt0RZgkRZAAs7/hFvRF6A9yTxFrypyJ+B/f6dVssYBEjLGIwtLWMgxlOgxSgKtBhFgRajKNBiFAVajKJAi1EUaDGKAi1GUaDFKAq0GEWBFqMo0GIUBVqMokCLUdL8PLTVBBzyr5wrVgKcCbuIYajGsVHhuu6ARUjSvWPlkOu6c8aooDFnWdauKNcHqtFvmnKIURRoMUq6gf6JL1WMnajXB6rRV2k9KRSJOk05xCgKtBhFgRajKNBiFAVajPL/1NmUu4VL2x4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 5\n",
      "iter    0   |   diff: 0.59049   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANu0lEQVR4nO3dfXBV9Z3H8ffv3Htz7s0DSSC5YBCNBgRtVTCALliBUSlauzIO2yHrMqziWmhLaemqHXemMtLB1pk6Th+GZaeO7bAl2Y6VbcdxWaq7tGyH0eHBEUWJihTCgyGEPD/cp7N/nDwYEpLc5J6H+8v39U/yu3POnO8988nJ7z6c31dZloUQujC8LkCITJJAC61IoIVWJNBCKxJooZXgSBsopR4HHrdHeZUwx+GShBhZfv5xWltb1eWPq3TetlNqvrV9+2MZLSxTNmxYD0B1dY3HlVxZVdVqAPbu/aPHlVzZ8uX3Av4+jwBPP/00J06cGBRomXIIrUighVYk0EIrEmihFQm00IoEWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCKBFpoZcTvQzvhQuICr7a9ysexj+myusg38ikLlrG6YDWlwVIvShpg4ycbaUg0DHr8uWufozxc7n5BQ1hzaA2fdX826PHtt26nIq/Cg4oG8uocehLoHc07OJM4w+yc2UQDUZqSTXwU/4jmVDOleB/oXrfl3UY0J9o3nhSY5GE1Q7u9+HbKwmV948JgoYfVDOb2OXQ90O2pds4kzhBRETYVbUIp+zvacSuOxZVvNgg0B7j6X6+m6W+aaF7U7ErlSwuXsqBgwai3D30YouDfC2hb1Ubs1hgM+vp55q2IrmDxlMXOHwgIng6SX51PbE6Mjr/tGNU+6Z7D8XI90GEVxlQmnVYn2xq3MTtnNjNDM7nRvBFTmVfcL9gaxKwzmfrqVEr/UErDVxtoWtzk6DPY17yPY53H+sZro2uH3T54Kkjo0xBFLxaRLEnS+g+tjgd7T/0e3m15t2+84boNGT9G8HSQ/F35mO+bEAeSjDrQ6Z7D8XI90AEVYM2kNfym6TfUJeqoS9TxJm9S3FbMtl3bmHN2hHsWE2B0G0z9j6mET4Y5v/a8Y7Uebj8M7f3jpzY9NeI+lrIwug2MMwaTfzyZpvVNdC3pcqzGty69NWCc6UAbFwxKnizBwkL1/GWG3w0zrWrasPsFvhOAosHnULtAA1SGK7klegsnz5ykVtXy5+CfuZR/iR3rdrAptmnIfcxzJlOrp6KSCitg0Tq3lYtfuehonZujm1l0cVHf+OLW4Y8X3h8m939ySRkpUNB+fzvdC7odrXFrzVbuWHcH1q3OLOmWmpKiaX0TBTUFqE6F0W0QnxGn5fGW4fdLpgB40niSytJKUkUpR+q7nOuBTlpJPo1/ysycmcyaMYtZzCLcHuaVtlfoCHfQVTb01SyZnwQFLZUtNHy1gXhp3PligxCfOfrjGI0GkT9FaL+/nY6vdGDlabBuoAFdS7rourOL8P+FKagpID4zPuJ5sT6xIAGJaQlSBe6EGTwIdNyK85NLP2FaYBozQjPIUTm80/UOAHPMK0834iVxal+ohYBblaave2E39ZX1vq5xzAL9wfbzpxeuBzqkQtydezfHY8d5r/s94lac4kAxS8JLWJ67fPidsyEo2VDjePj8+XnyonBVwSq3D5uWn1X8zOsSRrSzcicAoS0hEiQ8rmYwr86hj/95CJE+CbTQigRaaEUCLbQigRZakUALrXjy0bcYP+MVA3XI/m5F4KcBUjemSG1OTfhLlAQ6S6n3FeqwHWh1WmG0GKRSEugJ/vSzV/KRJITs362wRfLRpFyekEBnr2vAWmBhKQtMsO7V4ItQGSCBzmLJR5L2T7k695HTkM2ugcTOBEzxuhD/kEBnu+jIm0wkMuUQWkm7rRscdLAcIUZLYVlW+m3dlFKPK6UOKqUOwgVnahMiQ9K+QldX/7OD5Yxdb1NLVxbDGDP7XB858o7HdVzZvHlze37z83m0jekKLUQ2kUALrUighVYk0EIrEmihFQm00IoEWmhFAi20IoEWWpFAC61IoIVWJNBCKxJooRUJtNCK67dg+b6p5XeAIqAG+LDnsXLgH4Eu4EeeVDXI/Xvv51znuUGP1yytYXbhbA8quoxH59GzewqzoallNrhr6l1cnXd137g4p9jDarznWaDdbsioq5XXrmTZVcu8LsM3PAv0vuZ9HGs/1jeLd7p/XdrmYf+LBPDxP4/dJ3dzsKH/Ps8nbn7Cw2qG4PJ59CzQh9sPDxj7LtA+mIaOxv76/VDfP/ZdoF0+j54F+pk/PsPSvyzlfLVznWDHZagXMz60tWYrX/7elwnND3ldytBcPo/ytp3QigRaaEUCLbTi+hy6tyHjlF/6dIXBF4d47CSwxd0yRvL68tcBaNrS5HElV+DReZQrtNCKBFpoRQIttCKBFlqRQAutSKCFVlwPdPDTINHHooTq7I9qo+uihP8SdruMrNf+/Xaa7rLfsmv/ejstK1uw4tIJy/VApwpTqO7+ZX1VXJGcknS7jKxnRA37i/IAKeyehdIxx4NAT07RuaQTK2hhYRG/Nk58TtztMrKe+YgJgZ5BBCKbIyjl/0XKnebJHLrtoTZ7gfgcaH241YsSsp5RbGD+nQkGGNMNgnfI5Rk8CnRqcoqOuzuIzYrJ1XkczEdMVLEi8j25Ovfy7M+6da1cmcfLKDYofKPQ6zJ8Rd62E1qRQAutSONNkaWk8aaYANK+Qu/d+5yD5Yzd8uX3AtnR1PLs2cErHvlFWdlVPb/5/10TabwptCeBFlqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbQigRZakUALrUighVYk0EIrEmihFdfvKVxzaA2fdX826PHtt26nIq/C7XKG5PumlsDCXQupa6sb9Pjeh/byxZIvelDRZSZa483bi2+nLFzWNy4MjnCzpwV8BFTQvx6Fw9JtamnFLZIfJwne6N5pveeaeyifVN43nhLx6ULyLvEs0CuiK1g8ZfHodzgJoW+FsKZYJNclsZZZjgc73aaWsf+M0bmtk8BNASLfjRCc7/zprZpTxX3l9zl+nGzhWaD3nNvD0f89Ct32+JvHvjns9qpeYSkLdVER+GkAXoLk5iTWAufWc9v94W4O/O6AvdQW8O3abw+7feLtBIQgeSxJ28Y2AtcHyP1hLoHrnPvL23V4FwfOHugbP7voWceONSYTpfHmWy1vQf+Mg42/3jj6nWNAHNQHytFA72/ZDzP6x994+Rsj79Sb3RQkP0qSPJt0NNBvNrwJDf1j3wV6wjTenP3MgClHfO8IKyh9AsFvBSEAVqU97eAaZ2t8YeELA6ccDw6/ffdvu+l8vhNMMFeZmI+aGJOdfSNpa81Wqn5YRe6iXEePM2YuN97MngXRyiC1OkVqWcrxII9VcHEQ8zET82vOB1kMLXsCHYHU2pTXVQwrMD1AZH3E6zImNLmMCK24foXeWbnT7UOmrbeppZ+9/fdvA3B8y3GPK7kCabwpxPhJoIVWJNBCKxJooRUJtNCKBDpLJVuSxE/bn67Gz8VJXEh4XJE/ZM8HK2KAM2vP0HmkE4Dz3z2PCilmfTALleP/ZXCdJFfoLFXwYAEq2BPeFOTemTvhwwwS6KxVWFWIMu0AqxxF6dOlHlfkDxLoLGWYBiVPlIABuV/KxZxtel2SL8gcOosVVhXSsb+DkqdKvC7FNyTQWcwwDaa/NN3rMnxFphxCKxJooRVpvCmylDTeFBPAGK7QhxwsZzzs55ENTS3TOOWuU33XPP9/SCONN4X2JNBCKxJooRUJtNCKBFpoRQIttCKBFlqRQAutSKCFViTQQisSaKEVCbTQigRaaMXdW7A86l2XLt/3AATKXyznr81/HfT4ka8fYe60uR5UNITpwJ3YfWoiQAdQj/2V+g+cOaTcUziMbOgB+MAND1BR3N+wtDTXJ8sZ3ASswp4DXABqARM75DcjgfZCuj0A4+fitL7WSuHqQgIF7nQHXTdvHSvnrBz19s0Hmun8pJPo6ihG0KEZZwh4ADvMR4Hd9LXGQwEO3qTuTaBd7l03VtUfVqfVA7Dtv9u48OwFGp5vYPKGyRT/U7HjwX7pyEvsO7mvb/ziiqGWzu936rlTNP5XIyeeOsH1P77emWDPAHqbcv2J/jCDfR+Ggzc+eRNof7TLHtEbp94YMH541cMj7xQAq92i8eeNNP6ikem/nk7enXkOVQiv1b42YLzyvtFdrWNnY9Sur+XE908w/9B8cqbmZK6ozz/dpp6f92DPp3ttydzhPs+bQLvcu26sdnxhBzdvvRmru+eeqRH+EGPHY/a/2SQQgGA0SGCys1fol2e8zE0v3NT/wBeG377j/Q77F4W9Jt4cB9bEa//c75OARuAU8C5wS2YPdTmZQw8jOD1I+Z7yUW9/6VeXqP+XekLXhYj+IEre8jyUcvbevKJFRSx8dOGotz/64FEuvnaRomVFVDxfQcFtBZkv6jT2Oxq5wJeA32O/KGxBAp1NCr9WiDnLJLIo4niQx+qG7TcQ2xKjYJ4DQe4VB14HHsJ+vXQVUAcUOnfIXhLoDDJyDXIX+7RFcQ+zzMQsc2Fhx/ewr8iLsV8kzsWeinwMvO/cYWUZAxfJMgaZJcsYCO1JoIVWJNBCKxJooRUJtNCKBFpoRQIttCKBFlqRQAutSKCFViTQQisSaKEVCbTQigRaaEUCLbSS5vehVStw3Llyxq0EaPC6iBFIjZlxrWVZgxYhSfeOleOWZc3PUEEZp5Q66Of6QGp0mkw5hFYk0EIr6Qb63xypInP8Xh9IjY5K60WhEH4nUw6hFQm00IoEWmhFAi20IoEWWvl/eAvLNl1qMpsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 6\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 7\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 8\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 9\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.590 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iteration 29\n",
      "iter    0   |   diff: 0.00000   |   V(start): 0.198 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "mdp = FrozenLakeEnv(map_name='8x8', slip_chance=0.1)\n",
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(30):\n",
    "    clear_output(True)\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "    draw_policy(mdp, state_values)\n",
    "    sleep(0.5)\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 1.00000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.81000   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.65610   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.59049   |   V(start): 0.590 \n",
      "iter    6   |   diff: 0.00000   |   V(start): 0.590 \n",
      "average reward:  1.0\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "mdp = FrozenLakeEnv(slip_chance=0)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(1.0 <= np.mean(total_rewards) <= 1.0)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.90000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.72900   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.62330   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.50487   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.40894   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.34868   |   V(start): 0.349 \n",
      "iter    6   |   diff: 0.06529   |   V(start): 0.410 \n",
      "iter    7   |   diff: 0.05832   |   V(start): 0.468 \n",
      "iter    8   |   diff: 0.01139   |   V(start): 0.480 \n",
      "iter    9   |   diff: 0.00764   |   V(start): 0.487 \n",
      "iter   10   |   diff: 0.00164   |   V(start): 0.489 \n",
      "iter   11   |   diff: 0.00094   |   V(start): 0.490 \n",
      "iter   12   |   diff: 0.00022   |   V(start): 0.490 \n",
      "iter   13   |   diff: 0.00011   |   V(start): 0.490 \n",
      "iter   14   |   diff: 0.00003   |   V(start): 0.490 \n",
      "iter   15   |   diff: 0.00001   |   V(start): 0.490 \n",
      "iter   16   |   diff: 0.00000   |   V(start): 0.490 \n",
      "average reward:  0.885\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.1)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.8 <= np.mean(total_rewards) <= 0.95)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.75000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.50625   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.39867   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.26910   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.18164   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.14013   |   V(start): 0.140 \n",
      "iter    6   |   diff: 0.07028   |   V(start): 0.199 \n",
      "iter    7   |   diff: 0.06030   |   V(start): 0.260 \n",
      "iter    8   |   diff: 0.02594   |   V(start): 0.285 \n",
      "iter    9   |   diff: 0.01918   |   V(start): 0.305 \n",
      "iter   10   |   diff: 0.00858   |   V(start): 0.313 \n",
      "iter   11   |   diff: 0.00560   |   V(start): 0.319 \n",
      "iter   12   |   diff: 0.00260   |   V(start): 0.321 \n",
      "iter   13   |   diff: 0.00159   |   V(start): 0.323 \n",
      "iter   14   |   diff: 0.00076   |   V(start): 0.324 \n",
      "iter   15   |   diff: 0.00045   |   V(start): 0.324 \n",
      "iter   16   |   diff: 0.00022   |   V(start): 0.324 \n",
      "iter   17   |   diff: 0.00012   |   V(start): 0.325 \n",
      "iter   18   |   diff: 0.00006   |   V(start): 0.325 \n",
      "iter   19   |   diff: 0.00003   |   V(start): 0.325 \n",
      "iter   20   |   diff: 0.00002   |   V(start): 0.325 \n",
      "iter   21   |   diff: 0.00001   |   V(start): 0.325 \n",
      "average reward:  0.631\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.25)\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.7)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    0   |   diff: 0.80000   |   V(start): 0.000 \n",
      "iter    1   |   diff: 0.57600   |   V(start): 0.000 \n",
      "iter    2   |   diff: 0.41472   |   V(start): 0.000 \n",
      "iter    3   |   diff: 0.29860   |   V(start): 0.000 \n",
      "iter    4   |   diff: 0.24186   |   V(start): 0.000 \n",
      "iter    5   |   diff: 0.19349   |   V(start): 0.000 \n",
      "iter    6   |   diff: 0.15325   |   V(start): 0.000 \n",
      "iter    7   |   diff: 0.12288   |   V(start): 0.000 \n",
      "iter    8   |   diff: 0.09930   |   V(start): 0.000 \n",
      "iter    9   |   diff: 0.08037   |   V(start): 0.000 \n",
      "iter   10   |   diff: 0.06426   |   V(start): 0.000 \n",
      "iter   11   |   diff: 0.05129   |   V(start): 0.000 \n",
      "iter   12   |   diff: 0.04330   |   V(start): 0.000 \n",
      "iter   13   |   diff: 0.03802   |   V(start): 0.033 \n",
      "iter   14   |   diff: 0.03332   |   V(start): 0.058 \n",
      "iter   15   |   diff: 0.02910   |   V(start): 0.087 \n",
      "iter   16   |   diff: 0.01855   |   V(start): 0.106 \n",
      "iter   17   |   diff: 0.01403   |   V(start): 0.120 \n",
      "iter   18   |   diff: 0.00810   |   V(start): 0.128 \n",
      "iter   19   |   diff: 0.00555   |   V(start): 0.133 \n",
      "iter   20   |   diff: 0.00321   |   V(start): 0.137 \n",
      "iter   21   |   diff: 0.00247   |   V(start): 0.138 \n",
      "iter   22   |   diff: 0.00147   |   V(start): 0.139 \n",
      "iter   23   |   diff: 0.00104   |   V(start): 0.140 \n",
      "iter   24   |   diff: 0.00058   |   V(start): 0.140 \n",
      "iter   25   |   diff: 0.00036   |   V(start): 0.141 \n",
      "iter   26   |   diff: 0.00024   |   V(start): 0.141 \n",
      "iter   27   |   diff: 0.00018   |   V(start): 0.141 \n",
      "iter   28   |   diff: 0.00012   |   V(start): 0.141 \n",
      "iter   29   |   diff: 0.00007   |   V(start): 0.141 \n",
      "iter   30   |   diff: 0.00004   |   V(start): 0.141 \n",
      "iter   31   |   diff: 0.00003   |   V(start): 0.141 \n",
      "iter   32   |   diff: 0.00001   |   V(start): 0.141 \n",
      "iter   33   |   diff: 0.00001   |   V(start): 0.141 \n",
      "average reward:  0.743\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# Measure agent's average reward\n",
    "mdp = FrozenLakeEnv(slip_chance=0.2, map_name='8x8')\n",
    "state_values = value_iteration(mdp)\n",
    "\n",
    "total_rewards = []\n",
    "for game_i in range(1000):\n",
    "    s = mdp.reset()\n",
    "    rewards = []\n",
    "    for t in range(100):\n",
    "        s, r, done, _ = mdp.step(\n",
    "            get_optimal_action(mdp, state_values, s, gamma))\n",
    "        rewards.append(r)\n",
    "        if done:\n",
    "            break\n",
    "    total_rewards.append(np.sum(rewards))\n",
    "\n",
    "print(\"average reward: \", np.mean(total_rewards))\n",
    "assert(0.6 <= np.mean(total_rewards) <= 0.8)\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Part 1: Value iteration convergence\n",
    "\n",
    "### Find an MDP for which value iteration takes long to converge  (0.5 pts)\n",
    "\n",
    "When we ran value iteration on the small frozen lake problem, the last iteration where an action changed was iteration 6--i.e., value iteration computed the optimal policy at iteration 6. Are there any guarantees regarding how many iterations it'll take value iteration to compute the optimal policy? There are no such guarantees without additional assumptions--we can construct the MDP in such a way that the greedy policy will change after arbitrarily many iterations.\n",
    "\n",
    "Your task: define an MDP with at most 3 states and 2 actions, such that when you run value iteration, the optimal action changes at iteration >= 50. Use discount=0.95. (However, note that the discount doesn't matter here--you can construct an appropriate MDP with any discount.)\n",
    "\n",
    "Note: value function must change at least once after iteration >=50, not necessarily change on every iteration till >=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "rewards = {\n",
    "    < YOUR CODE >\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "from numpy import random\n",
    "mdp = MDP(transition_probs, rewards, initial_state=random.choice(tuple(transition_probs.keys())))\n",
    "# Feel free to change the initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = {s: 0 for s in mdp.get_all_states()}\n",
    "policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                   for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "for i in range(100):\n",
    "    print(\"after iteration %i\" % i)\n",
    "    state_values = value_iteration(mdp, state_values, num_iter=1)\n",
    "\n",
    "    new_policy = np.array([get_optimal_action(mdp, state_values, state, gamma)\n",
    "                           for state in sorted(mdp.get_all_states())])\n",
    "\n",
    "    n_changes = (policy != new_policy).sum()\n",
    "    print(\"N actions changed = %i \\n\" % n_changes)\n",
    "    policy = new_policy\n",
    "\n",
    "# please ignore iter 0 at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value iteration convervence proof (0.5 pts)\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "Update of value function in value iteration can be rewritten in a form of Bellman operator:\n",
    "\n",
    "$$(TV)(s) = \\max_{a \\in \\mathcal{A}}\\mathbb{E}\\left[ r_{t+1} + \\gamma V(s_{t+1}) | s_t = s, a_t = a\\right]$$\n",
    "\n",
    "Value iteration algorithm with Bellman operator:\n",
    "\n",
    "---\n",
    "&nbsp;&nbsp; Initialize $V_0$\n",
    "\n",
    "&nbsp;&nbsp; **for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V_{k+1} \\leftarrow TV_k$\n",
    "\n",
    "&nbsp;&nbsp;**end for**\n",
    "\n",
    "---\n",
    "\n",
    "In [lecture](https://docs.google.com/presentation/d/1lz2oIUTvd2MHWKEQSH8hquS66oe4MZ_eRvVViZs2uuE/edit#slide=id.g4fd6bae29e_2_4) we established contraction property of bellman operator:\n",
    "\n",
    "$$\n",
    "||TV - TU||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "Using contraction property of Bellman operator, Banach fixed-point theorem and Bellman equations prove that value function converges to $V^*$ in value iterateion$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus. Asynchronious value iteration (2 pts)\n",
    "\n",
    "Consider the following algorithm:\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $V_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select some state $s_k \\in \\mathcal{S}$    \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $V(s_k) := (TV)(s_k)$\n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Note that unlike common value iteration, here we update only a single state at a time.\n",
    "\n",
    "**Homework.** Prove the following proposition:\n",
    "\n",
    "If for all $s \\in \\mathcal{S}$, $s$ appears in the sequence $(s_0, s_1, ...)$ infinitely often, then $V$ converges to $V*$\n",
    "\n",
    "*<-- Your proof here -->*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW Part 2: Policy iteration\n",
    "\n",
    "## Policy iteration implementateion (2 pts)\n",
    "\n",
    "Let's implement exact policy iteration (PI), which has the following pseudocode:\n",
    "\n",
    "---\n",
    "Initialize $\\pi_0$   `// random or fixed action`\n",
    "\n",
    "For $n=0, 1, 2, \\dots$\n",
    "- Compute the state-value function $V^{\\pi_{n}}$\n",
    "- Using $V^{\\pi_{n}}$, compute the state-action-value function $Q^{\\pi_{n}}$\n",
    "- Compute new policy $\\pi_{n+1}(s) = \\operatorname*{argmax}_a Q^{\\pi_{n}}(s,a)$\n",
    "---\n",
    "\n",
    "Unlike VI, policy iteration has to maintain a policy - chosen actions from all states - and estimate $V^{\\pi_{n}}$ based on this policy. It only changes policy once values converged.\n",
    "\n",
    "\n",
    "Below are a few helpers that you may or may not use in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probs = {\n",
    "    's0': {\n",
    "        'a0': {'s0': 0.5, 's2': 0.5},\n",
    "        'a1': {'s2': 1}\n",
    "    },\n",
    "    's1': {\n",
    "        'a0': {'s0': 0.7, 's1': 0.1, 's2': 0.2},\n",
    "        'a1': {'s1': 0.95, 's2': 0.05}\n",
    "    },\n",
    "    's2': {\n",
    "        'a0': {'s0': 0.4, 's1': 0.6},\n",
    "        'a1': {'s0': 0.3, 's1': 0.3, 's2': 0.4}\n",
    "    }\n",
    "}\n",
    "rewards = {\n",
    "    's1': {'a0': {'s0': +5}},\n",
    "    's2': {'a1': {'s0': -1}}\n",
    "}\n",
    "\n",
    "from mdp import MDP\n",
    "mdp = MDP(transition_probs, rewards, initial_state='s0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function called `compute_vpi` that computes the state-value function $V^{\\pi}$ for an arbitrary policy $\\pi$.\n",
    "\n",
    "Unlike VI, this time you must find the exact solution, not just a single iteration.\n",
    "\n",
    "Recall that $V^{\\pi}$ satisfies the following linear equation:\n",
    "$$V^{\\pi}(s) = \\sum_{s'} P(s,\\pi(s),s')[ R(s,\\pi(s),s') + \\gamma V^{\\pi}(s')]$$\n",
    "\n",
    "You'll have to solve a linear system in your code. (Find an exact solution, e.g., with `np.linalg.solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vpi(mdp, policy, gamma):\n",
    "    \"\"\"\n",
    "    Computes V^pi(s) FOR ALL STATES under given policy.\n",
    "    :param policy: a dict of currently chosen actions {s : a}\n",
    "    :returns: a dict {state : V^pi(state) for all states}\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy = {s: np.random.choice(\n",
    "    mdp.get_possible_actions(s)) for s in mdp.get_all_states()}\n",
    "new_vpi = compute_vpi(mdp, test_policy, gamma)\n",
    "\n",
    "print(new_vpi)\n",
    "\n",
    "assert type(\n",
    "    new_vpi) is dict, \"compute_vpi must return a dict {state : V^pi(state) for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've got new state values, it's time to update our policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_policy(mdp, vpi, gamma):\n",
    "    \"\"\"\n",
    "    Computes new policy as argmax of state values\n",
    "    :param vpi: a dict {state : V^pi(state) for all states}\n",
    "    :returns: a dict {state : optimal action for all states}\n",
    "    \"\"\"\n",
    "    <YOUR CODE >\n",
    "    return < YOUR CODE >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_policy = compute_new_policy(mdp, new_vpi, gamma)\n",
    "\n",
    "print(new_policy)\n",
    "\n",
    "assert type(\n",
    "    new_policy) is dict, \"compute_new_policy must return a dict {state : optimal action for all states}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Main loop__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(mdp, policy=None, gamma=0.9, num_iter=1000, min_difference=1e-5):\n",
    "    \"\"\" \n",
    "    Run the policy iteration loop for num_iter iterations or till difference between V(s) is below min_difference.\n",
    "    If policy is not given, initialize it at random.\n",
    "    \"\"\"\n",
    "    < A WHOLE LOT OF YOUR CODE >\n",
    "\n",
    "    return state_values, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your PI Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "< Compare PI and VI on the MDP from bonus 1, then on small & large FrozenLake >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy iteration convergnece (3 pts)\n",
    "\n",
    "**Note:** Assume that $\\mathcal{S}, \\mathcal{A}$ are finite.\n",
    "\n",
    "We can define another Bellman operator:\n",
    "\n",
    "$$(T_{\\pi}V)(s) = \\mathbb{E}_{r, s'|s, a = \\pi(s)}\\left[r + \\gamma V(s')\\right]$$\n",
    "\n",
    "And rewrite policy iteration algorithm in operator form:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Initialize $\\pi_0$\n",
    "\n",
    "**for** $k = 0,1,2,...$ **do**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Solve $V_k = T_{\\pi_k}V_k$   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Select $\\pi_{k+1}$ s.t. $T_{\\pi_{k+1}}V_k = TV_k$ \n",
    "\n",
    "**end for**\n",
    "\n",
    "---\n",
    "\n",
    "To prove convergence of the algorithm we need to prove two properties: contraction an monotonicity.\n",
    "\n",
    "#### Monotonicity (0.5 pts)\n",
    "\n",
    "For all $V, U$ if $V(s) \\le U(s)$   $\\forall s \\in \\mathcal{S}$ then $(T_\\pi V)(s) \\le (T_\\pi U)(s)$   $\\forall s \\in  \\mathcal{S}$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Contraction (1 pts)\n",
    "\n",
    "$$\n",
    "||T_\\pi V - T_\\pi U||_{\\infty} \\le \\gamma ||V - U||_{\\infty}\n",
    "$$\n",
    "\n",
    "For all $V, U$\n",
    "\n",
    "*<-- Your proof here -->*\n",
    "\n",
    "#### Convergence (1.5 pts)\n",
    "\n",
    "Prove that there exists iteration $k_0$ such that $\\pi_k = \\pi^*$ for all $k \\ge k_0$\n",
    "\n",
    "*<-- Your proof here -->*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
